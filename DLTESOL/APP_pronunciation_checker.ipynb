{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOP34ACFNcr8hGJ4Bmii5S6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Spring2024/blob/main/DLTESOL/APP_pronunciation_checker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \t🐳 **Pronunciation checker (Sample)**\n",
        "\n",
        "- Implementing pronunciation correction in a language learning application is quite advanced. It typically involves speech recognition to transcribe the user's spoken input and then compares it with the expected correct pronunciation. Here's a basic approach using Python:\n",
        "\n",
        "  + Speech Recognition: Use a library like speech_recognition to capture and transcribe spoken input.\n",
        "  + Comparison with Expected Pronunciation: Compare the transcribed text with the correct text.\n",
        "  + Feedback to User: Provide feedback based on the comparison."
      ],
      "metadata": {
        "id": "TmnBPdDv_X6f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ SpeechRecognition is for capturing and transcribing audio. python-Levenshtein provides a way to measure the difference between two sequences (in our case, spoken and expected text)."
      ],
      "metadata": {
        "id": "Hxx-Kods_5Ok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1] Installation"
      ],
      "metadata": {
        "id": "ihjv9rrD8QFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install SpeechRecognition\n",
        "!pip install python-Levenshtein\n",
        "!pip install gTTS pydub\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "exUYyUxn_oFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define TTS to generate sample audio\n",
        "\n",
        "**Note:**\n",
        "\n",
        "+ gTTS audio file generates 'mp3' file format, which is not recognized in SpeechRecognition.\n",
        "+ Thus, we use additional code to convert 'mp3' to 'WAV'"
      ],
      "metadata": {
        "id": "_7KJaiW6_8N_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tts(text, lang='en'):\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    tts.save(\"output.mp3\")\n",
        "    AudioSegment.from_mp3(\"output.mp3\").export(\"output.wav\", format=\"wav\")\n",
        "    return Audio(\"output.wav\")\n",
        "\n",
        "def ktts(text, lang=\"ko\"):\n",
        "    ktts = gTTS(text=text, lang=lang)\n",
        "    ktts.save(\"k-output.mp3\")\n",
        "    AudioSegment.from_mp3(\"k-output.mp3\").export(\"k-output.wav\", format=\"wav\")\n",
        "    return Audio(\"k-output.wav\")"
      ],
      "metadata": {
        "id": "5IrrLdbO5dBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate audio in Korean accent.\n",
        "text = \"Upload your assignment to our E-learning website.\"\n",
        "ktts(text)"
      ],
      "metadata": {
        "id": "kOfLzIqu6Bd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Provide expected text to evaluate the speech:\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import ratio\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    # Initialize the recognizer\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    # Open the audio file\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        print(\"Transcribing the audio file...\")\n",
        "        audio = r.record(source)  # Instead of listening, we now use record to capture the whole file\n",
        "\n",
        "    # Use Google Web Speech API to transcribe\n",
        "    try:\n",
        "        text = r.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return \"Could not request results; {0}\".format(e)\n",
        "\n",
        "def pronunciation_correction(expected_text, file_path):\n",
        "    user_spoken_text = transcribe_audio(file_path)\n",
        "    print(\"Transcribed Text: \" + user_spoken_text)\n",
        "\n",
        "    # Compare the spoken text with the expected text\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())\n",
        "    print(f\"Similarity: {similarity}\")\n",
        "    if similarity > 0.8:  # You can adjust this threshold\n",
        "        return \"Good pronunciation!\"\n",
        "    else:\n",
        "        return \"Try again, make sure to pronounce clearly.\"\n",
        "\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "correct_text = input()\n",
        "audio_file_path = \"/content/k-output.wav\"  # Replace with the path to your audio file\n",
        "feedback = pronunciation_correction(correct_text, audio_file_path)\n",
        "print(feedback)\n",
        "\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# # Assuming you uploaded a file named 'speech.wav'\n",
        "# audio_file_path = uploaded\n",
        "# feedback = pronunciation_correction(correct_text, audio_file_path)\n",
        "# print(feedback)\n"
      ],
      "metadata": {
        "id": "tQxlXtqu__ep",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revise the code to work with an uploaded file"
      ],
      "metadata": {
        "id": "Csd3VgK6-eU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Type the text to refer to for speech recognition (expected speech)\n",
        "from google.colab import files\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import ratio\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    # Initialize the recognizer\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    # Open the audio file\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        print(\"Transcribing the audio file...\")\n",
        "        audio = r.record(source)  # Instead of listening, we now use record to capture the whole file\n",
        "\n",
        "    # Use Google Web Speech API to transcribe\n",
        "    try:\n",
        "        text = r.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return \"Could not request results; {0}\".format(e)\n",
        "\n",
        "def pronunciation_correction(expected_text, file_path):\n",
        "    user_spoken_text = transcribe_audio(file_path)\n",
        "    print(\"Transcribed Text: \" + user_spoken_text)\n",
        "\n",
        "    # Compare the spoken text with the expected text\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())\n",
        "    print(f\"Similarity: {similarity}\")\n",
        "    if similarity > 0.8:  # You can adjust this threshold\n",
        "        return \"Good pronunciation!\"\n",
        "    else:\n",
        "        return \"Try again, make sure to pronounce clearly.\"\n",
        "\n",
        "# Example Usage\n",
        "correct_text = input(\"Please provide the expected text: \")\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload a file from your computer\n",
        "\n",
        "# Assuming you uploaded a single file, extract the filename\n",
        "file_name = next(iter(uploaded))\n",
        "feedback = pronunciation_correction(correct_text, file_name)\n",
        "print(feedback)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "01qCJfgq-cqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio link"
      ],
      "metadata": {
        "id": "CIO749Q4_gLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "O2B4f6xT_jz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gradio below works well (2024.02.17)"
      ],
      "metadata": {
        "id": "aPTHzzqoGJrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import ratio\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "def transcribe_audio(file_info):\n",
        "    r = sr.Recognizer()\n",
        "\n",
        "    # file_info[0] is the file name, file_info[1] is the NumPy array\n",
        "    # Save the NumPy array to a temporary WAV file\n",
        "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".wav\") as tmpfile:\n",
        "        sf.write(file=tmpfile.name, data=file_info[1], samplerate=44100, format='WAV')\n",
        "        tmpfile.seek(0)\n",
        "\n",
        "        with sr.AudioFile(tmpfile.name) as source:\n",
        "            audio_data = r.record(source)\n",
        "\n",
        "    try:\n",
        "        text = r.recognize_google(audio_data)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Could not request results; {e}\"\n",
        "\n",
        "def pronunciation_correction(expected_text, file_info):\n",
        "    user_spoken_text = transcribe_audio(file_info)\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())\n",
        "    if similarity > 0.8:\n",
        "        return \"Good pronunciation!\", similarity\n",
        "    else:\n",
        "        return \"Try again, make sure to pronounce clearly.\", similarity\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=pronunciation_correction,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Expected Text\"),\n",
        "        gr.Audio(label=\"Upload Audio File\", type=\"numpy\")  # Specify type=\"numpy\" to ensure file_info[1] is a NumPy array\n",
        "    ],\n",
        "    outputs=[\"text\", \"number\"],\n",
        "    title=\"Pronunciation Correction Tool\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "G0c12ZYx_hdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How it Works\n",
        "This code uses Google's Web Speech API to transcribe it.\n",
        "The pronunciation_correction function takes the expected correct text, records the user's speech, and compares the transcription to the expected text.\n",
        "The similarity is measured using the Levenshtein ratio. If the similarity is above a certain threshold, it considers the pronunciation good."
      ],
      "metadata": {
        "id": "xzCQkVUIANnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Considerations\n",
        "+ Accuracy: Speech recognition accuracy can vary based on accent, speech clarity, and background noise.\n",
        "+ Language Support: Google's speech recognition supports multiple languages, but you need to specify the language if it's not English.\n",
        "+ Privacy: Inform users that their speech will be sent to Google's servers for transcription.\n",
        "+ Improvement: For more advanced pronunciation analysis, you might consider phonetic comparison or integrating specialized APIs."
      ],
      "metadata": {
        "id": "40oXbhDWAPLM"
      }
    }
  ]
}