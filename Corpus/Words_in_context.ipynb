{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPWIf//UcVEEteWGptFJGcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Spring2024/blob/main/Corpus/Words_in_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçÉ Words in context\n",
        "\n",
        "+ Analyzing words in context is fundamental for accurately interpreting and understanding language, whether in human communication, language learning, or computational language processing."
      ],
      "metadata": {
        "id": "BC4851Myyn8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key methods"
      ],
      "metadata": {
        "id": "lo9JNoMwz_Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Tokenization\n",
        "+ Part-of-Speech (POS) Tagging\n",
        "+ Contextual Word Meaning (Word Sense Disambiguation)\n",
        "+ Concordance view\n",
        "+ Collocations\n",
        "+ Sentiment analysis"
      ],
      "metadata": {
        "id": "mYQFYbPP0C--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## {nltk} installation"
      ],
      "metadata": {
        "id": "B9mFGmLr0h9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "qGi1OEvQ0hox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Tokenization\n",
        "\n",
        "+ Purpose: Breaking down text into individual words (tokens) is the first step in many NLP tasks.\n",
        "+ Method: Use nltk.word_tokenize() for tokenizing sentences into words."
      ],
      "metadata": {
        "id": "WJjs8pWk1EMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown fox jumps over the lazy dog\""
      ],
      "metadata": {
        "id": "kzln7GQ50uf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMBTSz_yi17"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "QSCmaGF30-mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-Speech (POS) Tagging\n",
        "\n",
        "+ Purpose: Assigning parts of speech to each word (like noun, verb, adjective) helps in understanding the grammatical context.\n",
        "+ Method: Use nltk.pos_tag().\n",
        "+ [Penn Treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
      ],
      "metadata": {
        "id": "mUv_Z0T91ANX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "2fY4uJTy1dtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "5IXJE9j_1SRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] Contextual Word Meaning (Word Sense Disambiguation):\n",
        "\n",
        "+ Purpose: Determining the meaning of a word based on the context it appears in.\n",
        "+ Method: Use algorithms like Lesk Algorithm implemented in NLTK.\n",
        "\n",
        "Note: NLTK uses [WordNet](https://wordnet.princeton.edu)"
      ],
      "metadata": {
        "id": "quRKdtmQ2HA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Bank (Meaning 1 - Financial Institution):\n",
        "\n",
        "  + Sentence 1: I need to visit the bank to withdraw some money.\n",
        "  + Sentence 2: The bank of the river was a peaceful place to relax.\n",
        "+ Bat (Meaning 1 - Nocturnal Flying Mammal):\n",
        "\n",
        "  + Sentence 1: I saw a bat flying in the night sky.\n",
        "  + Sentence 2: She used a baseball bat to hit the ball out of the park.\n",
        "+ Book (Meaning 1 - Written or Printed Work):\n",
        "\n",
        "  + Sentence 1: I'm reading a fascinating book about space exploration.\n",
        "  + Sentence 2: Please book a table for two at the restaurant for tonight.\n",
        "+ Crane (Meaning 1 - Bird with a Long Neck):\n",
        "\n",
        "  + Sentence 1: A beautiful crane waded in the shallow water.\n",
        "  + Sentence 2: They used a crane to lift the heavy machinery onto the truck.\n",
        "+ Club (Meaning 1 - Social Organization):\n",
        "\n",
        "  + Sentence 1: I'm a member of the local chess club.\n",
        "  + Sentence 2: He used a golf club to hit the ball into the hole."
      ],
      "metadata": {
        "id": "E_rYv9ZJ3yLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = input(\"Paste a sentence: \")\n",
        "amb = input(\"Type target word: \")"
      ],
      "metadata": {
        "id": "0dowCbih4Kk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = sent\n",
        "ambiguous = amb\n",
        "word_sense = lesk(word_tokenize(sentence), ambiguous)\n",
        "\n",
        "# Access the name of the disambiguated sense\n",
        "print(\"Disambiguated Sense:\", word_sense.name())\n",
        "# Access the definition of the disambiguated sense\n",
        "print(\"Sense Definition:\", word_sense.definition())\n"
      ],
      "metadata": {
        "id": "LyXk0_gx1_XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Define the sentence and ambiguous word\n",
        "sentence = \"He addressed the issue.\"\n",
        "ambiguous = \"address\"\n",
        "\n",
        "# Tokenize the sentence and perform POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Filter tokens based on the POS tag of the ambiguous word\n",
        "filtered_tokens = [token for token, pos in pos_tags if pos == 'POS_TAG_OF_AMBIGUOUS_WORD']\n",
        "\n",
        "# Perform Word Sense Disambiguation using Lesk algorithm\n",
        "word_sense = lesk(filtered_tokens, ambiguous)\n",
        "\n",
        "# Access the name of the disambiguated sense\n",
        "print(\"Disambiguated Sense:\", word_sense.name())\n",
        "# Access the definition of the disambiguated sense\n",
        "print(\"Sense Definition:\", word_sense.definition())\n"
      ],
      "metadata": {
        "id": "Q--8GuPz7Sry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "fRzJ9LU98inl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "sentence = \"Your addressed the issue clearly.\"\n",
        "ambiguous_word = \"addressed\"\n",
        "\n",
        "# Define a function to map Penn Treebank POS tags to WordNet POS tags\n",
        "def penn_to_wordnet_pos(penn_pos):\n",
        "    if penn_pos.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif penn_pos.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif penn_pos.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    elif penn_pos.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    else:\n",
        "        return None  # Return None for unknown POS tags\n",
        "\n",
        "# Define your sentence and ambiguous word\n",
        "sentence = \"The invalid is in the hospital.\"\n",
        "ambiguous_word = \"invalid\"\n",
        "\n",
        "# Tokenize the sentence and perform POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Determine the Penn Treebank POS tag for the ambiguous word\n",
        "ambiguous_word_pos_penn = None\n",
        "\n",
        "for token, pos in pos_tags:\n",
        "    if token == ambiguous_word:\n",
        "        ambiguous_word_pos_penn = pos\n",
        "        break\n",
        "\n",
        "# Map the Penn Treebank POS tag to WordNet POS tag\n",
        "ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "\n",
        "if ambiguous_word_pos_wordnet is None:\n",
        "    print(f\"Cannot determine WordNet POS category for '{ambiguous_word_pos_penn}'.\")\n",
        "else:\n",
        "    # Retrieve synsets and disambiguate sense\n",
        "    synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "    if synsets:\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        print(\"Disambiguated Sense:\", word_sense.name())\n",
        "        print(\"Sense Definition:\", word_sense.definition())\n",
        "    else:\n",
        "        print(f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\")\n"
      ],
      "metadata": {
        "id": "NweKOui59FfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio"
      ],
      "metadata": {
        "id": "pIFHPo14-w39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "jpQshXAV-2UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Gradio app to display the ambiguous meaning (Not so reliable)\n",
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Define a function to map Penn Treebank POS tags to WordNet POS tags\n",
        "def penn_to_wordnet_pos(penn_pos):\n",
        "    if penn_pos.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif penn_pos.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif penn_pos.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    elif penn_pos.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    else:\n",
        "        return None  # Return None for unknown POS tags\n",
        "\n",
        "# Define the disambiguation function that uses POS tagging\n",
        "def disambiguate_word_sense(sentence, ambiguous_word):\n",
        "    # Tokenize the sentence and perform POS tagging\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    # Find the POS tag for the ambiguous word in the tokenized sentence\n",
        "    ambiguous_word_pos_penn = None\n",
        "    for word, pos in pos_tags:\n",
        "        if word.lower() == ambiguous_word.lower():\n",
        "            ambiguous_word_pos_penn = pos\n",
        "            break\n",
        "\n",
        "    # If the POS tag is found, convert to WordNet POS tag\n",
        "    if ambiguous_word_pos_penn:\n",
        "        ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "    else:\n",
        "        return \"The ambiguous word was not found in the sentence.\"\n",
        "\n",
        "    if ambiguous_word_pos_wordnet:\n",
        "        # Perform Word Sense Disambiguation using Lesk algorithm\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        if word_sense:\n",
        "            return f\"Disambiguated Sense: {word_sense.name()}\\nSense Definition: {word_sense.definition()}\"\n",
        "        else:\n",
        "            return f\"No disambiguated sense found for '{ambiguous_word}'.\"\n",
        "    else:\n",
        "        return f\"Cannot determine WordNet POS category for '{ambiguous_word}'.\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=2, placeholder=\"Enter a sentence containing the ambiguous word\", label=\"Sentence\"),\n",
        "        gr.Textbox(placeholder=\"Enter the ambiguous word\", label=\"Ambiguous Word\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence and an ambiguous word to disambiguate its sense.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "o0LwagpzMBeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With POS (Just to get an idea)"
      ],
      "metadata": {
        "id": "8TtAnYv2Pq0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Gradio app with POS info to display the ambiguous meaning (Not so reliable)\n",
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Ensure NLTK data is available\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')  # Open Multilingual Wordnet\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(sentence, ambiguous_word, pos_choice):\n",
        "    # Map POS choice to WordNet POS\n",
        "    pos_map = {\n",
        "        \"Noun\": wordnet.NOUN,\n",
        "        \"Verb\": wordnet.VERB,\n",
        "        \"Adjective\": wordnet.ADJ,\n",
        "        \"Adverb\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    # Determine WordNet POS based on the user's choice\n",
        "    wordnet_pos = pos_map.get(pos_choice)\n",
        "\n",
        "    if wordnet_pos is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{pos_choice}'.\"\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    # Use lesk to disambiguate the sense of the word\n",
        "    disambiguated_sense = lesk(tokens, ambiguous_word, pos=wordnet_pos)\n",
        "\n",
        "    if disambiguated_sense:\n",
        "        sense_name = disambiguated_sense.name()\n",
        "        sense_definition = disambiguated_sense.definition()  # Get the definition of the selected sense\n",
        "        return f\"Disambiguated Sense: {sense_name}\\nSense Definition: {sense_definition}\"\n",
        "    else:\n",
        "        return f\"No suitable sense found for '{ambiguous_word}' with POS '{pos_choice}'.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Sentence\", placeholder=\"Enter a sentence containing the ambiguous word\"),\n",
        "        gr.Textbox(label=\"Ambiguous Word\", placeholder=\"Enter the ambiguous word\"),\n",
        "        gr.Dropdown(label=\"Select POS\", choices=[\"Noun\", \"Verb\", \"Adjective\", \"Adverb\"])\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence, an ambiguous word, and select the part of speech (POS) of the word.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R-3pFy6dK0z4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}