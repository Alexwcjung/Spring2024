{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNI3UDNNMO0uEvX/BJJm7+6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Spring2024/blob/main/Corpus/Words_in_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçÉ Words in context\n",
        "\n",
        "+ Analyzing words in context is fundamental for accurately interpreting and understanding language, whether in human communication, language learning, or computational language processing."
      ],
      "metadata": {
        "id": "BC4851Myyn8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key methods"
      ],
      "metadata": {
        "id": "lo9JNoMwz_Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Tokenization\n",
        "+ Part-of-Speech (POS) Tagging\n",
        "+ Contextual Word Meaning (Word Sense Disambiguation)\n",
        "+ Concordance view\n",
        "+ Collocations\n",
        "+ Sentiment analysis"
      ],
      "metadata": {
        "id": "mYQFYbPP0C--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## {nltk} installation"
      ],
      "metadata": {
        "id": "B9mFGmLr0h9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "qGi1OEvQ0hox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Tokenization\n",
        "\n",
        "+ Purpose: Breaking down text into individual words (tokens) is the first step in many NLP tasks.\n",
        "+ Method: Use nltk.word_tokenize() for tokenizing sentences into words."
      ],
      "metadata": {
        "id": "WJjs8pWk1EMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The quick brown fox jumps over the lazy dog\""
      ],
      "metadata": {
        "id": "kzln7GQ50uf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtMBTSz_yi17"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "QSCmaGF30-mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part-of-Speech (POS) Tagging\n",
        "\n",
        "+ Purpose: Assigning parts of speech to each word (like noun, verb, adjective) helps in understanding the grammatical context.\n",
        "+ Method: Use nltk.pos_tag().\n",
        "+ [Penn Treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)"
      ],
      "metadata": {
        "id": "mUv_Z0T91ANX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "2fY4uJTy1dtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "id": "5IXJE9j_1SRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] Contextual Word Meaning (Word Sense Disambiguation):\n",
        "\n",
        "+ Purpose: Determining the meaning of a word based on the context it appears in.\n",
        "+ Method: Use algorithms like Lesk Algorithm implemented in NLTK.\n",
        "\n",
        "Note: NLTK uses [WordNet](https://wordnet.princeton.edu)"
      ],
      "metadata": {
        "id": "quRKdtmQ2HA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Bank (Meaning 1 - Financial Institution):\n",
        "\n",
        "  + Sentence 1: I need to visit the bank to withdraw some money.\n",
        "  + Sentence 2: The bank of the river was a peaceful place to relax.\n",
        "+ Bat (Meaning 1 - Nocturnal Flying Mammal):\n",
        "\n",
        "  + Sentence 1: I saw a bat flying in the night sky.\n",
        "  + Sentence 2: She used a baseball bat to hit the ball out of the park.\n",
        "+ Book (Meaning 1 - Written or Printed Work):\n",
        "\n",
        "  + Sentence 1: I'm reading a fascinating book about space exploration.\n",
        "  + Sentence 2: Please book a table for two at the restaurant for tonight.\n",
        "+ Crane (Meaning 1 - Bird with a Long Neck):\n",
        "\n",
        "  + Sentence 1: A beautiful crane waded in the shallow water.\n",
        "  + Sentence 2: They used a crane to lift the heavy machinery onto the truck.\n",
        "+ Club (Meaning 1 - Social Organization):\n",
        "\n",
        "  + Sentence 1: I'm a member of the local chess club.\n",
        "  + Sentence 2: He used a golf club to hit the ball into the hole."
      ],
      "metadata": {
        "id": "E_rYv9ZJ3yLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = input(\"Paste a sentence: \")\n",
        "amb = input(\"Type target word: \")"
      ],
      "metadata": {
        "id": "0dowCbih4Kk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = sent\n",
        "ambiguous = amb\n",
        "word_sense = lesk(word_tokenize(sentence), ambiguous)\n",
        "\n",
        "# Access the name of the disambiguated sense\n",
        "print(\"Disambiguated Sense:\", word_sense.name())\n",
        "# Access the definition of the disambiguated sense\n",
        "print(\"Sense Definition:\", word_sense.definition())\n"
      ],
      "metadata": {
        "id": "LyXk0_gx1_XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Define the sentence and ambiguous word\n",
        "sentence = \"He addressed the issue.\"\n",
        "ambiguous = \"address\"\n",
        "\n",
        "# Tokenize the sentence and perform POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Filter tokens based on the POS tag of the ambiguous word\n",
        "filtered_tokens = [token for token, pos in pos_tags if pos == 'POS_TAG_OF_AMBIGUOUS_WORD']\n",
        "\n",
        "# Perform Word Sense Disambiguation using Lesk algorithm\n",
        "word_sense = lesk(filtered_tokens, ambiguous)\n",
        "\n",
        "# Access the name of the disambiguated sense\n",
        "print(\"Disambiguated Sense:\", word_sense.name())\n",
        "# Access the definition of the disambiguated sense\n",
        "print(\"Sense Definition:\", word_sense.definition())\n"
      ],
      "metadata": {
        "id": "Q--8GuPz7Sry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Your addressed the issue clearly.\"\n",
        "ambiguous_word = \"addressed\"\n"
      ],
      "metadata": {
        "id": "fRzJ9LU98inl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Define a function to map Penn Treebank POS tags to WordNet POS tags\n",
        "def penn_to_wordnet_pos(penn_pos):\n",
        "    if penn_pos.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif penn_pos.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif penn_pos.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    elif penn_pos.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    else:\n",
        "        return None  # Return None for unknown POS tags\n",
        "\n",
        "# Define your sentence and ambiguous word\n",
        "sentence = \"The invalid is in the hospital.\"\n",
        "ambiguous_word = \"invalid\"\n",
        "\n",
        "# Tokenize the sentence and perform POS tagging\n",
        "tokens = word_tokenize(sentence)\n",
        "pos_tags = pos_tag(tokens)\n",
        "\n",
        "# Determine the Penn Treebank POS tag for the ambiguous word\n",
        "ambiguous_word_pos_penn = None\n",
        "\n",
        "for token, pos in pos_tags:\n",
        "    if token == ambiguous_word:\n",
        "        ambiguous_word_pos_penn = pos\n",
        "        break\n",
        "\n",
        "# Map the Penn Treebank POS tag to WordNet POS tag\n",
        "ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "\n",
        "if ambiguous_word_pos_wordnet is None:\n",
        "    print(f\"Cannot determine WordNet POS category for '{ambiguous_word_pos_penn}'.\")\n",
        "else:\n",
        "    # Retrieve synsets and disambiguate sense\n",
        "    synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "    if synsets:\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        print(\"Disambiguated Sense:\", word_sense.name())\n",
        "        print(\"Sense Definition:\", word_sense.definition())\n",
        "    else:\n",
        "        print(f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\")\n"
      ],
      "metadata": {
        "id": "NweKOui59FfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio"
      ],
      "metadata": {
        "id": "pIFHPo14-w39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "jpQshXAV-2UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def disambiguate_word_sense(sentence, ambiguous_word):\n",
        "    def penn_to_wordnet_pos(penn_pos):\n",
        "        if penn_pos.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif penn_pos.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif penn_pos.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        elif penn_pos.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ambiguous_word_pos_penn = None\n",
        "\n",
        "    for token, pos in pos_tags:\n",
        "        if token == ambiguous_word:\n",
        "            ambiguous_word_pos_penn = pos\n",
        "            break\n",
        "\n",
        "    ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{ambiguous_word_pos_penn}'.\"\n",
        "    else:\n",
        "        synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "        if synsets:\n",
        "            word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "            disambiguated_sense = word_sense.name()\n",
        "            sense_definition = word_sense.definition()\n",
        "            return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {sense_definition}\"\n",
        "        else:\n",
        "            return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\"text\", \"text\"],\n",
        "    outputs=\"text\",\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence and an ambiguous word to disambiguate its sense.\",\n",
        "    live=True\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "t3z837d3-yFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(input_data):\n",
        "    sentence, ambiguous_word = input_data[\"sentence\"], input_data[\"ambiguous_word\"]\n",
        "\n",
        "    def penn_to_wordnet_pos(penn_pos):\n",
        "        if penn_pos.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif penn_pos.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif penn_pos.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        elif penn_pos.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ambiguous_word_pos_penn = None\n",
        "\n",
        "    for token, pos in pos_tags:\n",
        "        if token == ambiguous_word:\n",
        "            ambiguous_word_pos_penn = pos\n",
        "            break\n",
        "\n",
        "    ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{ambiguous_word_pos_penn}'.\"\n",
        "    else:\n",
        "        synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "        if synsets:\n",
        "            word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "            disambiguated_sense = word_sense.name()\n",
        "            sense_definition = word_sense.definition()\n",
        "            return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {sense_definition}\"\n",
        "        else:\n",
        "            return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(text=\"Enter a sentence\", label=\"Sentence\"),\n",
        "        gr.Textbox(text=\"Enter an ambiguous word\", label=\"Ambiguous Word\")\n",
        "    ],\n",
        "    outputs=gr.outputs.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence and an ambiguous word to disambiguate its sense.\",\n",
        "    live=False  # Set live=False to include a submit button\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "CAEd_dia_ohn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(sentence, ambiguous_word):\n",
        "\n",
        "    def penn_to_wordnet_pos(penn_pos):\n",
        "        if penn_pos.startswith('N'):\n",
        "            return wordnet.NOUN\n",
        "        elif penn_pos.startswith('V'):\n",
        "            return wordnet.VERB\n",
        "        elif penn_pos.startswith('R'):\n",
        "            return wordnet.ADV\n",
        "        elif penn_pos.startswith('J'):\n",
        "            return wordnet.ADJ\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "    ambiguous_word_pos_penn = None\n",
        "\n",
        "    for token, pos in pos_tags:\n",
        "        if token == ambiguous_word:\n",
        "            ambiguous_word_pos_penn = pos\n",
        "            break\n",
        "\n",
        "    ambiguous_word_pos_wordnet = penn_to_wordnet_pos(ambiguous_word_pos_penn)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{ambiguous_word_pos_penn}'.\"\n",
        "    else:\n",
        "        synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "        if synsets:\n",
        "            word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "            disambiguated_sense = word_sense.name()\n",
        "            sense_definition = word_sense.definition()\n",
        "            return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {sense_definition}\"\n",
        "        else:\n",
        "            return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Sentence\", placeholder=\"Enter a sentence\"),\n",
        "        gr.Textbox(label=\"Ambiguous Word\", placeholder=\"Enter an ambiguous word\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence and an ambiguous word to disambiguate its sense.\",\n",
        "    live=False  # Set live=False to include a submit button\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "tu_F-zU7_ykK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "ambiguous_word = \"teach\"\n",
        "\n",
        "# Get synsets for the ambiguous word\n",
        "synsets = wordnet.synsets(ambiguous_word)\n",
        "\n",
        "# Print all senses and their definitions\n",
        "for i, synset in enumerate(synsets):\n",
        "    print(f\"Sense {i+1}:\")\n",
        "    print(\"Definition:\", synset.definition())\n"
      ],
      "metadata": {
        "id": "-6Owt2wxBPJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(sentence, ambiguous_word, pos_choice):\n",
        "\n",
        "    # Map POS choice to WordNet POS\n",
        "    pos_map = {\n",
        "        \"Noun\": wordnet.NOUN,\n",
        "        \"Verb\": wordnet.VERB,\n",
        "        \"Adjective\": wordnet.ADJ,\n",
        "        \"Adverb\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    # Determine WordNet POS based on the user's choice\n",
        "    ambiguous_word_pos_wordnet = pos_map.get(pos_choice)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{pos_choice}'.\"\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "    if synsets:\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        disambiguated_sense = word_sense.name()\n",
        "        sense_definition = word_sense.definition()\n",
        "        return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {sense_definition}\"\n",
        "    else:\n",
        "        return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Sentence\", placeholder=\"Enter a sentence\"),\n",
        "        gr.Textbox(label=\"Ambiguous Word\", placeholder=\"Enter an ambiguous word\"),\n",
        "        gr.Dropdown(label=\"Select POS\", choices=[\"Noun\", \"Verb\", \"Adjective\", \"Adverb\"])\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence, an ambiguous word, and select the part of speech (POS) of the word.\",\n",
        "    live=False  # Set live=False to include a submit button\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "fS1i4xyRC7sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a function to get the definition of a WordNet sense\n",
        "def get_sense_definition(sense):\n",
        "    try:\n",
        "        return sense.definition()\n",
        "    except:\n",
        "        return \"Definition not found.\"\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(sentence, ambiguous_word, pos_choice):\n",
        "\n",
        "    # Map POS choice to WordNet POS\n",
        "    pos_map = {\n",
        "        \"Noun\": wordnet.NOUN,\n",
        "        \"Verb\": wordnet.VERB,\n",
        "        \"Adjective\": wordnet.ADJ,\n",
        "        \"Adverb\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    # Determine WordNet POS based on the user's choice\n",
        "    ambiguous_word_pos_wordnet = pos_map.get(pos_choice)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{pos_choice}'.\"\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "    if synsets:\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        disambiguated_sense = word_sense.name()\n",
        "        sense_definition = get_sense_definition(word_sense)  # Get the definition of the selected sense\n",
        "        return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {sense_definition}\"\n",
        "    else:\n",
        "        return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Sentence\", placeholder=\"Enter a sentence\"),\n",
        "        gr.Textbox(label=\"Ambiguous Word\", placeholder=\"Enter an ambiguous word\"),\n",
        "        gr.Dropdown(label=\"Select POS\", choices=[\"Noun\", \"Verb\", \"Adjective\", \"Adverb\"])\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence, an ambiguous word, and select the part of speech (POS) of the word.\",\n",
        "    live=False  # Set live=False to include a submit button\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "6_g_QGqmD16J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.wsd import lesk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define the disambiguation function\n",
        "def disambiguate_word_sense(sentence, ambiguous_word, pos_choice):\n",
        "\n",
        "    # Map POS choice to WordNet POS\n",
        "    pos_map = {\n",
        "        \"Noun\": wordnet.NOUN,\n",
        "        \"Verb\": wordnet.VERB,\n",
        "        \"Adjective\": wordnet.ADJ,\n",
        "        \"Adverb\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    # Determine WordNet POS based on the user's choice\n",
        "    ambiguous_word_pos_wordnet = pos_map.get(pos_choice)\n",
        "\n",
        "    if ambiguous_word_pos_wordnet is None:\n",
        "        return f\"Cannot determine WordNet POS category for '{pos_choice}'.\"\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "\n",
        "    synsets = wordnet.synsets(ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "\n",
        "    if synsets:\n",
        "        word_sense = lesk(tokens, ambiguous_word, pos=ambiguous_word_pos_wordnet)\n",
        "        disambiguated_sense = word_sense.name()\n",
        "\n",
        "        # Get definitions of all synsets for the ambiguous word\n",
        "        synset_definitions = [synset.definition() for synset in synsets]\n",
        "\n",
        "        # Match the Disambiguated Sense to the correct definition\n",
        "        matched_definition = None\n",
        "        for definition in synset_definitions:\n",
        "            if disambiguated_sense in definition:\n",
        "                matched_definition = definition\n",
        "                break\n",
        "\n",
        "        if matched_definition:\n",
        "            return f\"Disambiguated Sense: {disambiguated_sense}\\nSense Definition: {matched_definition}\"\n",
        "        else:\n",
        "            return \"Definition not found for the disambiguated sense.\"\n",
        "    else:\n",
        "        return f\"No synsets found for '{ambiguous_word}' in the '{ambiguous_word_pos_wordnet}' category.\"\n",
        "\n",
        "# Create a Gradio interface with a submit button\n",
        "iface = gr.Interface(\n",
        "    fn=disambiguate_word_sense,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Sentence\", placeholder=\"Enter a sentence\"),\n",
        "        gr.Textbox(label=\"Ambiguous Word\", placeholder=\"Enter an ambiguous word\"),\n",
        "        gr.Dropdown(label=\"Select POS\", choices=[\"Noun\", \"Verb\", \"Adjective\", \"Adverb\"])\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Result\"),\n",
        "    title=\"Word Sense Disambiguation\",\n",
        "    description=\"Enter a sentence, an ambiguous word, and select the part of speech (POS) of the word.\",\n",
        "    live=False  # Set live=False to include a submit button\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "Vo2Mn885EqlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}